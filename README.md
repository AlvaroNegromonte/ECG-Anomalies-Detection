# Detec√ß√£o de Anomalias Cardiol√≥gicas em ECG (PTB-XL) ‚Äî 2025.1

Este reposit√≥rio cont√©m o desenvolvimento de um pipeline de **classifica√ß√£o de ECG** usando a base **PTB-XL** (Kaggle) e modelos de **Aprendizado de M√°quina/Deep Learning**. O notebook principal implementa:
- preparo do dataset,
- pr√©-processamento dos sinais,
- extra√ß√£o de caracter√≠sticas (FFT, DWT, entropia de Shannon e estat√≠sticas no tempo),
- treinamento de **CNN 1D**,
- avalia√ß√£o (matrizes de confus√£o, curvas ROC, an√°lise de overfitting),
- compara√ß√£o com baseline (ex.: varia√ß√£o ‚ÄúFFT-only‚Äù).

## üéØ Objetivo
Classificar registros de ECG em tr√™s classes:
- **MI** ‚Äî Infarto Agudo do Mioc√°rdio  
- **Abn-HB** ‚Äî Batimento Card√≠aco Anormal (Arritmias)  
- **NORM** ‚Äî ECG Normal

> Essas classes aparecem no in√≠cio do notebook, que tamb√©m justifica a escolha cl√≠nica e a import√¢ncia de incluir a classe ‚Äúnormal‚Äù.

## üìÇ Estrutura do reposit√≥rio
```
Projeto_Sinais_2025_1.ipynb     # Notebook principal (renomear se necess√°rio)
README.md                       # Este arquivo
```

Durante a execu√ß√£o no Colab, o notebook cria/usa pastas e arquivos como:
```
/content/ptb-xl-dataset/...                  # dados baixados do Kaggle
/content/splited_dataset/
    X_signals.npy
    y_labels.npy
    X_filtered.npy
    y_filtered.npy
/content/cnn_metrics/                        # m√©tricas/artefatos dos testes (se√ß√µes de treino)
```

## üß∞ Depend√™ncias principais
Executar no **Google Colab** √© recomendado. Bibliotecas usadas no notebook:
- `numpy`, `pandas`, `matplotlib`, `seaborn`, `scipy`
- **Sinais/ECG**: `wfdb`, `pywt` (Wavelets)
- **ML/DL**: `tensorflow/keras`, `scikit-learn`
- Utilit√°rios: `pydub`, `zipfile`, `shutil`, `pickle`
- **Kaggle API** (para baixar a PTB-XL diretamente no Colab)

## ‚ñ∂Ô∏è Como executar (Colab)
1. **Abra o notebook no Colab**  
   [![Abrir no Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/usuario/repositorio/blob/main/Projeto_Sinais_2025_1.ipynb)  
   > Substitua `usuario/repositorio` pelo seu reposit√≥rio no GitHub, e considere **renomear o arquivo** para `Projeto_Sinais_2025_1.ipynb` (sem espa√ßos) antes do push.

2. **Configure a Kaggle API** (primeiras c√©lulas da se√ß√£o ‚ÄúImporting Dataset from Kaggle‚Äù):  
   - Fa√ßa upload do `kaggle.json` no Colab (Conta Kaggle ‚Üí API ‚Üí Create New Token).  
   - Rode as c√©lulas que copiam o token para `~/.kaggle` e definem permiss√µes.  
   - Execute o download:
     ```
     kaggle datasets download -d khyeh0719/ptb-xl-dataset
     unzip -o ptb-xl-dataset.zip -d /content/ptb-xl-dataset
     ```
3. **Processe os dados** seguindo as c√©lulas da se√ß√£o ‚ÄúProcessamento da Base PTB-XL‚Äù / ‚ÄúPr√©-processamento dos sinais‚Äù.  
   O notebook gera arrays `.npy` em `/content/splited_dataset/` para acelerar experimentos.

4. **Rode os Testes (1‚Äì7)**  
   Cada ‚ÄúTeste‚Äù configura uma varia√ß√£o (ex.: arquitetura/hiperpar√¢metros/feature set).  
   Ao final, o notebook plota **curvas de treino/valida√ß√£o**, **matrizes de confus√£o**, **curvas ROC** e faz **an√°lise textual** (overfitting, ponto de parada, implica√ß√µes).

## üîß Pipeline (resumo)
- **Pr√©-processamento**  
  Normaliza√ß√£o (`StandardScaler` por canal), estabilidade de amostras, janelamento dos sinais (entrada t√≠pica reportada no notebook: **407√ó12** amostras√óderiva√ß√µes, podendo variar conforme o teste).
- **Aumento de dados (Data Augmentation)**  
  Ru√≠do gaussiano, **time-shift** (deslocamento temporal), **escala de amplitude** e **invers√£o** opcional.
- **Extra√ß√£o de caracter√≠sticas**  
  - **FFT** (espectro por deriva√ß√£o, compress√£o log, sele√ß√£o de bins)  
  - **DWT** (ex.: Daubechies, n√≠veis configur√°veis; coeficientes por canal)  
  - **Entropia de Shannon** (em janelas/espectro)  
  - Estat√≠sticas no tempo (ex.: m√©dia, vari√¢ncia, **skewness**, **kurtosis**)
- **Modelo principal ‚Äî CNN 1D**  
  Arquitetura t√≠pica descrita nas se√ß√µes de teste: pilha de `Conv1D` + `BatchNorm` + `LeakyReLU` + `Dropout`, seguida de `GlobalAveragePooling1D` e `Dense` final.  
  *Treino com* **EarlyStopping**, `StratifiedKFold`/hold-out e **class weights** para lidar com desbalanceamento.
- **Baseline/Comparativos**  
  Vers√£o **FFT-only** e varia√ß√µes; compara√ß√£o qualitativa e via m√©tricas.

## üìà Avalia√ß√£o
- **Matrizes de confus√£o** por teste/classe  
- **Curvas ROC** (one-vs-rest) com **AUC**  
- Curvas **Loss/Accuracy** (treino √ó valida√ß√£o), an√°lise de **overfitting** e ponto de **early stopping**  
- Coment√°rios sobre **generaliza√ß√£o** e **vi√©s** das abordagens

## üîÅ Reprodutibilidade
O notebook fixa seeds (`numpy`, `random`, `tensorflow`) em v√°rias se√ß√µes. A ordem e a **execu√ß√£o sequencial** das c√©lulas √© importante para replicar os resultados.

## üë• Equipe
- Vin√≠cius de Sousa Rodrigues (vsr)  
- √Ålvaro Cavalcante Negromonte (acn3)  
- J√∫lio C√©sar Barbosa da Silva (jcbs3)  
- Luiz Felipe Silva Lustosa (lfsl)  
- Felipe Torres de Macedo (ftm2)  
- Edinaldo Filho (ebcf2)

> **Observa√ß√£o √©tica**: O projeto usa a base p√∫blica PTB-XL e √© voltado a fins acad√™micos. Resultados n√£o devem ser usados como ferramenta diagn√≥stica cl√≠nica.
