{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzJPvquB4S6o"
      },
      "source": [
        "# **Problemas cardiológicos selecionados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zecCanY34h2C"
      },
      "source": [
        "O modelo será treinado para reconhecer três condições distintas nos registros de ECG da base PTB-XL:\n",
        "\n",
        "1. Infarto Agudo do Miocárdio (MI)\n",
        "\n",
        "  - Condição grave com alterações claras na morfologia do complexo QRS e segmento ST.\n",
        "\n",
        "2. Batimento Cardíaco Anormal (Abnormal Heartbeat – Abn-HB)\n",
        "\n",
        "  - Irregularidades no ritmo cardíaco, incluindo extrassístoles, fibrilações e taquiarritmias.\n",
        "\n",
        "3. ECG Normal (NORM)\n",
        "\n",
        "  - Representa pacientes saudáveis, sem evidências de anomalias eletrocardiográficas.\n",
        "\n",
        "A inclusão da classe “normal” é essencial para permitir que o modelo aprenda a distinguir padrões fisiológicos normais de padrões patológicos. Isso garante completude diagnóstica e redução de falsos positivos, além de estar em conformidade com a especificação oficial do projeto: “diagnóstico de anomalias cardiológicas e também coração normal”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTZzbC7x4uvC"
      },
      "source": [
        "---\n",
        "# **Pré-processamento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZiqe2Ls44ry"
      },
      "source": [
        "## Instalando bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHQqkmzuXaKc",
        "outputId": "2bf9aa5d-06d4-4957-f9c0-04e1530a1b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: wfdb in /home/vinicius/.local/lib/python3.10/site-packages (4.3.0)\n",
            "Requirement already satisfied: pandas in /home/vinicius/.local/lib/python3.10/site-packages (2.3.1)\n",
            "Requirement already satisfied: numpy in /home/vinicius/.local/lib/python3.10/site-packages (2.2.6)\n",
            "Requirement already satisfied: scipy in /home/vinicius/.local/lib/python3.10/site-packages (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /home/vinicius/.local/lib/python3.10/site-packages (3.10.3)\n",
            "Requirement already satisfied: scikit-learn in /home/vinicius/.local/lib/python3.10/site-packages (1.7.1)\n",
            "Collecting seaborn\n",
            "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Requirement already satisfied: PyWavelets in /home/vinicius/.local/lib/python3.10/site-packages (1.8.0)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.10.0 in /home/vinicius/.local/lib/python3.10/site-packages (from wfdb) (2025.7.0)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/lib/python3/dist-packages (from wfdb) (2.25.1)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /home/vinicius/.local/lib/python3.10/site-packages (from wfdb) (3.12.14)\n",
            "Requirement already satisfied: soundfile>=0.10.0 in /home/vinicius/.local/lib/python3.10/site-packages (from wfdb) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vinicius/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/vinicius/.local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/lib/python3/dist-packages (from matplotlib) (9.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vinicius/.local/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/vinicius/.local/lib/python3.10/site-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/vinicius/.local/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/vinicius/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/vinicius/.local/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vinicius/.local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/vinicius/.local/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vinicius/.local/lib/python3.10/site-packages (from aiohttp>=3.10.11->wfdb) (6.6.3)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /home/vinicius/.local/lib/python3.10/site-packages (from aiohttp>=3.10.11->wfdb) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/vinicius/.local/lib/python3.10/site-packages (from aiohttp>=3.10.11->wfdb) (1.7.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vinicius/.local/lib/python3.10/site-packages (from aiohttp>=3.10.11->wfdb) (1.20.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/vinicius/.local/lib/python3.10/site-packages (from aiohttp>=3.10.11->wfdb) (0.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/vinicius/.local/lib/python3.10/site-packages (from aiohttp>=3.10.11->wfdb) (25.3.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/vinicius/.local/lib/python3.10/site-packages (from aiohttp>=3.10.11->wfdb) (5.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vinicius/.local/lib/python3.10/site-packages (from aiohttp>=3.10.11->wfdb) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /home/vinicius/.local/lib/python3.10/site-packages (from soundfile>=0.10.0->wfdb) (1.17.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /home/vinicius/.local/lib/python3.10/site-packages (from aiosignal>=1.4.0->aiohttp>=3.10.11->wfdb) (4.14.1)\n",
            "Requirement already satisfied: pycparser in /home/vinicius/.local/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.10.0->wfdb) (2.22)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.10.11->wfdb) (3.3)\n",
            "Installing collected packages: tqdm, seaborn\n",
            "Successfully installed seaborn-0.13.2 tqdm-4.67.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install wfdb pandas numpy scipy matplotlib scikit-learn seaborn PyWavelets tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tf6Z12z497r"
      },
      "source": [
        "---\n",
        "## Processamento da Base PTB-XL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tratamento dos dados "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Essa primeira etapa realiza a importação, organização, balanceamento e salvamento dos dados do dataset [PTB-XL](https://physionet.org/content/ptb-xl/1.0.3/), uma base pública de eletrocardiogramas, incluindo exames com infarto (MI), batimentos anormais (Abn-HB) e normalidade (NORM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Feitos do código abaixo:\n",
        "    1. Importa os metadados do arquivo ptbxl_database.csv\n",
        "    2. Classifica os exames em três categorias clínicas:\n",
        "    - MI: Infarto do miocárdio (com base nos códigos SCP)\n",
        "    - Abn-HB: Batimentos anormais (como PVC, LBBB, PAC)\n",
        "    - NORM: Eletrocardiogramas normais\n",
        "    3. Seleciona uma amostra balanceada com até 100 exames por classe\n",
        "    4. Carrega os sinais de ECG brutos (500 Hz) usando o wfdb\n",
        "    5. Salva os sinais e rótulos como arquivos .npy em data_preprocessed/\n",
        "\n",
        "- Saídas:\n",
        "    1. `data_preprocessed/X_signals.npy`: Lista de sinais ECG brutos (array de objetos NumPy)\n",
        "    2. `data_preprocessed/y_labels.npy`: Lista de rótulos (MI, Abn-HB, NORM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CT12pEuh5EwT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classe 'MI': usando 100 de 5469 disponíveis.\n",
            "Classe 'Abn-HB': usando 100 de 2222 disponíveis.\n",
            "Classe 'NORM': usando 100 de 8748 disponíveis.\n",
            "\n",
            "Carregando 300 sinais balanceados...\n",
            "\n",
            "Dados salvos em: /home/vinicius/projetos/ptbxl/data_preprocessed\n",
            "   - 300 sinais\n",
            "   - Distribuição: {np.str_('Abn-HB'): np.int64(100), np.str_('MI'): np.int64(100), np.str_('NORM'): np.int64(100)}\n",
            "\n",
            "Distribuição de classes (conjunto total):\n",
            "target\n",
            "NORM      8748\n",
            "MI        5469\n",
            "Abn-HB    2222\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Bibliotecas necessárias\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wfdb            # para carregar os sinais .dat/.hea\n",
        "import ast             # para converter string → dicionário (scp_codes)\n",
        "\n",
        "# Caminhos principais do projeto\n",
        "BASE_DIR = os.path.expanduser('~/projetos/ptbxl')                   # diretório base do projeto\n",
        "RECORDS_PATH = os.path.join(BASE_DIR, 'records500')                 # onde estão os sinais ECG\n",
        "METADATA_CSV = os.path.join(BASE_DIR, 'ptbxl_database.csv')         # metadados dos exames\n",
        "SCP_STATEMENTS_CSV = os.path.join(BASE_DIR, 'scp_statements.csv')   # mapeia códigos SCP\n",
        "DATA_OUT_PATH = os.path.join(BASE_DIR, 'data_preprocessed')         # onde salvar o dataset pronto\n",
        "\n",
        "# Criação da pasta de saída \n",
        "os.makedirs(DATA_OUT_PATH, exist_ok=True)\n",
        "\n",
        "# Carrega o CSV de metadados e converte scp_codes de string para dict\n",
        "def load_metadata():\n",
        "    df = pd.read_csv(METADATA_CSV)\n",
        "    df['scp_codes'] = df['scp_codes'].apply(ast.literal_eval)\n",
        "    return df\n",
        "\n",
        "# Mapeia os códigos SCP para três classes clínicas: MI, Abn-HB, NORM\n",
        "def extract_labels(df):\n",
        "    \n",
        "    # Lê os significados dos códigos SCP e filtra os que são infarto (MI)\n",
        "    scp_df = pd.read_csv(SCP_STATEMENTS_CSV, index_col=0)\n",
        "    mi_scp_codes = scp_df[scp_df['diagnostic_class'] == 'MI'].index.tolist()\n",
        "\n",
        "    # Define os códigos de batimentos anormais\n",
        "    abn_scp_codes = ['ABQRS', 'PVC', 'PAC', 'LBBB', 'RBBB', 'IRBBB']\n",
        "\n",
        "    # Função auxiliar para atribuir rótulo com base nos códigos presentes\n",
        "    def map_label(codes):\n",
        "        labels = list(codes.keys())\n",
        "        if any(label in mi_scp_codes for label in labels):\n",
        "            return 'MI'\n",
        "        elif any(label in abn_scp_codes for label in labels):\n",
        "            return 'Abn-HB'\n",
        "        elif 'NORM' in labels:\n",
        "            return 'NORM'\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    # Aplica o mapeamento e remove exames sem classe definida\n",
        "    df['target'] = df['scp_codes'].apply(map_label)\n",
        "    return df[df['target'].notnull()]\n",
        "\n",
        "# Carrega o sinal de ECG a partir de um caminho relativo (filename_hr)\n",
        "def load_signal(record_path):\n",
        "    full_path = os.path.join(BASE_DIR, record_path)\n",
        "    signal, _ = wfdb.rdsamp(full_path)\n",
        "    return signal\n",
        "\n",
        "# Carrega um subconjunto balanceado de sinais com as três classes\n",
        "def load_dataset_balanced(sample_limit_per_class=100):\n",
        "    df = extract_labels(load_metadata())\n",
        "\n",
        "    dfs = []\n",
        "    for class_name in ['MI', 'Abn-HB', 'NORM']:\n",
        "        df_class = df[df['target'] == class_name]\n",
        "        available = len(df_class)\n",
        "        if available == 0:\n",
        "            print(f\"Classe '{class_name}' indisponível na base.\")\n",
        "            continue\n",
        "        n = min(sample_limit_per_class, available)\n",
        "        print(f\"Classe '{class_name}': usando {n} de {available} disponíveis.\")\n",
        "        dfs.append(df_class.sample(n=n, random_state=42))  # amostragem aleatória\n",
        "\n",
        "    # Une os subconjuntos e embaralha os dados\n",
        "    df_sampled = pd.concat(dfs).sample(frac=1, random_state=42)\n",
        "\n",
        "    X_signals = []  # lista de sinais ECG\n",
        "    y_labels = []   # lista de rótulos\n",
        "\n",
        "    print(f\"\\nCarregando {len(df_sampled)} sinais balanceados...\")\n",
        "\n",
        "    # Carrega os sinais reais dos arquivos .dat/.hea\n",
        "    for _, row in df_sampled.iterrows():\n",
        "        try:\n",
        "            signal = load_signal(row['filename_hr'])\n",
        "            X_signals.append(signal)\n",
        "            y_labels.append(row['target'])\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao carregar {row['filename_hr']}: {e}\")\n",
        "\n",
        "    return np.array(X_signals, dtype=object), np.array(y_labels)\n",
        "\n",
        "# Salva os sinais e rótulos em arquivos .npy\n",
        "def save_dataset(X, y):\n",
        "    np.save(os.path.join(DATA_OUT_PATH, 'X_signals.npy'), X)\n",
        "    np.save(os.path.join(DATA_OUT_PATH, 'y_labels.npy'), y)\n",
        "    print(f\"\\nDados salvos em: {DATA_OUT_PATH}\")\n",
        "    print(f\"   - {len(X)} sinais\")\n",
        "    print(f\"   - Distribuição: {dict(zip(*np.unique(y, return_counts=True)))}\")\n",
        "\n",
        "# Execução principal (para analisar a distribuição)\n",
        "if __name__ == \"__main__\":\n",
        "    X, y = load_dataset_balanced(sample_limit_per_class=100)\n",
        "    save_dataset(X, y)\n",
        "\n",
        "    # Exibe a distribuição geral das classes no conjunto total\n",
        "    dff = load_metadata()\n",
        "    dff = extract_labels(dff)\n",
        "    print(\"\\nDistribuição de classes (conjunto total):\")\n",
        "    print(dff['target'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Visualização dos arquivos gerados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Arquivo X_signals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(300, 5000, 12)\n",
            "(5000, 12)\n",
            "[[-0.095 -0.01 0.085 ... 0.105 -0.115 -0.05]\n",
            " [-0.095 -0.01 0.085 ... 0.105 -0.115 -0.05]\n",
            " [-0.095 -0.01 0.085 ... 0.105 -0.115 -0.05]\n",
            " ...\n",
            " [0.26 0.18 -0.08 ... 0.695 0.46 0.395]\n",
            " [0.26 0.18 -0.08 ... 0.695 0.46 0.395]\n",
            " [0.26 0.18 -0.08 ... 0.695 0.46 0.395]]\n"
          ]
        }
      ],
      "source": [
        "X = np.load('data_preprocessed/X_signals.npy', allow_pickle=True)\n",
        "\n",
        "print(type(X))                 # <class 'numpy.ndarray'>\n",
        "print(X.shape)                 # (300,)  ← 300 exames (cada um é um array 2D)\n",
        "print(X[0].shape)              # (5000, 12)  ← 5000 amostras, 12 derivações\n",
        "print(X[0])                    # mostra o sinal do primeiro exame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Formato: cada elemento do array é um sinal ECG de um exame, carregado a partir dos arquivos .dat e .hea.\n",
        "- Dimensão de cada item: (n_amostras, n_derivações), geralmente (5000, 12) para 10 segundos de ECG a 500 Hz com 12 derivações.\n",
        "- Tamanho do array: 100 por classe (3 classes: MI, Abn-HB, NORM), então o total é 300 sinais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "#### Arquivo y_signals "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(300,)\n",
            "['Abn-HB' 'MI' 'NORM']\n",
            "NORM\n"
          ]
        }
      ],
      "source": [
        "y = np.load('data_preprocessed/y_labels.npy', allow_pickle=True)\n",
        "\n",
        "print(type(y))         # <class 'numpy.ndarray'>\n",
        "print(y.shape)         # (300,)\n",
        "print(np.unique(y))    # ['Abn-HB' 'MI' 'NORM']\n",
        "print(y[0])            # rótulo do primeiro sinal em X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Tipo: numpy.ndarray de strings\n",
        "- Formato: vetor unidimensional com o rótulo correspondente a cada sinal em X_signals.npy.\n",
        "- Valores possíveis: 'MI', 'Abn-HB', 'NORM'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
